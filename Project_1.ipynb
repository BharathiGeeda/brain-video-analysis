{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dMmZj7OIk1rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # HISTORY\n",
        "\n",
        "#### Largest Dataset Mapping Human Brain\n",
        "* In collaboration with the Lichtman Laboratory at Harvard University, Google is releasing the “H01” dataset, a 1.4 petabyte rendering of a small sample of human brain tissue, along with a companion paper, “A connectomic study of a petascale fragment of human cerebral cortex.” The H01 sample was imaged at 4nm-resolution by serial section electron microscopy, reconstructed and annotated by automated computational techniques, and analyzed for preliminary insights into the structure of the human cortex. The dataset comprises imaging data that covers roughly one cubic millimeter of brain tissue, and includes tens of thousands of reconstructed neurons, millions of neuron fragments, 130 million annotated synapses, 104 proofread cells, and many additional subcellular annotations and structures — all easily accessible with the Neuroglancer browser interface.\n",
        "\n",
        "* This dataset contains videos of specific networks.\n",
        "* It is shared for the first time in the given link. It is suitable for Computer Vision and DCGAN structures.\n",
        "\n",
        "#### INCLUDE\n",
        "\n",
        "* Full Connected\n",
        "* Hemibrain Connection\n",
        "* EM\n",
        "* Central Complex Structures\n",
        "* Connects Regions: ADL02od PCT\n",
        "* Connects Regions: ADM10t\n",
        "* Connects Regions: APL\n",
        "* Connects Regions: AVL01lo PCT\n",
        "* Connects Regions: ExR3\n",
        "* Connects Regions: MBON01\n",
        "* Connects Regions: Olfactory LN\n",
        "* Connects Regions: Ovil N\n",
        "\n",
        "\n",
        "\n",
        "https://h01-release.storage.googleapis.com/landing.html"
      ],
      "metadata": {
        "id": "OfbueZE7uwHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PACKAGES AND LIBRARIES"
      ],
      "metadata": {
        "id": "SDucPE1ru8M1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "#PATH PROCESS\n",
        "import os\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "import glob\n",
        "#IMAGE PROCESS\n",
        "from PIL import Image\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import imageio\n",
        "from IPython.display import Image\n",
        "import matplotlib.image as mpimg\n",
        "from skimage.transform import resize\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "import zipfile\n",
        "from io import BytesIO\n",
        "from nibabel import FileHolder\n",
        "from nibabel.analyze import AnalyzeImage\n",
        "import PIL\n",
        "from IPython import display\n",
        "from skimage.morphology import convex_hull_image, erosion\n",
        "from skimage.morphology import square\n",
        "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
        "from skimage import data, io, filters\n",
        "import skimage\n",
        "#SCALER & TRANSFORMATION\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import regularizers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#ACCURACY CONTROL\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "#OPTIMIZER\n",
        "from keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n",
        "#MODEL LAYERS\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n",
        "                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\n",
        "LSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU, ReLU\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "from keras.applications import VGG16,VGG19,inception_v3\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "from keras.datasets import mnist\n",
        "import keras\n",
        "#IGNORING WARNINGS\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "filterwarnings(\"ignore\", category=FutureWarning) \n",
        "filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "vTMjZW43lQCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA EXPORTATION AND TRANSFORMATION"
      ],
      "metadata": {
        "id": "Gp3FymU6vDs0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VIDEO PATH"
      ],
      "metadata": {
        "id": "NZsBid7CvG5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ADL02od_PCT = \"drive/My Drive/Brain_Data_Video_IDDCR/ADL02od_pct.mp4\"\n",
        "ADM10t = \"drive/My Drive/Brain_Data_Video_IDDCR/ADM10t.mp4\"\n",
        "APL = \"drive/My Drive/Brain_Data_Video_IDDCR/APL.mp4\"\n",
        "AVL01lo_PCT = \"drive/My Drive/Brain_Data_Video_IDDCR/AVL01lo_pct.mp4\"\n",
        "Central_Complex_One = \"drive/My Drive/Brain_Data_Video_IDDCR/Central_Complex.mp4\"\n",
        "Central_Complex_Two = \"drive/My Drive/Brain_Data_Video_IDDCR/Central_Complex_Two.mp4\"\n",
        "EM = \"drive/My Drive/Brain_Data_Video_IDDCR/EM_Data.mp4\"\n",
        "ExR3 = \"drive/My Drive/Brain_Data_Video_IDDCR/ExR3.mp4\"\n",
        "Full_Connected = \"drive/My Drive/Brain_Data_Video_IDDCR/Full_Connected.mp4\"\n",
        "Hemibrain = \"drive/My Drive/Brain_Data_Video_IDDCR/Hemibrain.mp4\"\n",
        "MBON01 = \"drive/My Drive/Brain_Data_Video_IDDCR/MBON01.mp4\"\n",
        "Olfactory_LN = \"drive/My Drive/Brain_Data_Video_IDDCR/olfactory_LN.mp4\"\n",
        "OvilN = \"drive/My Drive/Brain_Data_Video_IDDCR/ovilN.mp4\""
      ],
      "metadata": {
        "id": "SqIecMj8lmrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TRANSFORMATION SPECIFIC NEURON"
      ],
      "metadata": {
        "id": "6Pai14C8vXxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Neuron_List = [ADL02od_PCT,ADM10t,APL,AVL01lo_PCT,ExR3,MBON01,Olfactory_LN,OvilN]"
      ],
      "metadata": {
        "id": "wJ5JqFaPlyvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Neuron_IMG = []\n",
        "\n",
        "for neuron_video in Neuron_List:\n",
        "    \n",
        "    Video_Path = neuron_video\n",
        "    \n",
        "    Video_Caption = cv2.VideoCapture(Video_Path)\n",
        "    \n",
        "    while Video_Caption.isOpened():\n",
        "        \n",
        "        _,frame = Video_Caption.read()\n",
        "        \n",
        "        if _ != True:\n",
        "            break\n",
        "            \n",
        "        if Video_Caption.isOpened():\n",
        "            \n",
        "            Transformation_IMG = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "            Resized_IMG = cv2.resize(Transformation_IMG,(180,180))\n",
        "            Neuron_IMG.append(Resized_IMG)\n",
        "            \n",
        "    Video_Caption.release()"
      ],
      "metadata": {
        "id": "NOd4nikZl39J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Neuron_IMG))"
      ],
      "metadata": {
        "id": "LJ0gX50Bl6XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(np.array(Neuron_IMG)))"
      ],
      "metadata": {
        "id": "aWFQi3k1l8zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TRANSFORMATION EM"
      ],
      "metadata": {
        "id": "vdM3z67ivcxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EM_IMG = []\n",
        "\n",
        "Video_Path = EM\n",
        "\n",
        "Video_Caption = cv2.VideoCapture(Video_Path)\n",
        "\n",
        "while Video_Caption.isOpened():\n",
        "    \n",
        "    _,frame = Video_Caption.read()\n",
        "    \n",
        "    if _ != True:\n",
        "        break\n",
        "    if Video_Caption.isOpened():\n",
        "        Transformation_IMG = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "        Resized_IMG = cv2.resize(Transformation_IMG,(180,180))\n",
        "        EM_IMG.append(Resized_IMG)"
      ],
      "metadata": {
        "id": "X5DlLuWUm7Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(EM_IMG))"
      ],
      "metadata": {
        "id": "ajAGK_u1m-DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(np.array(EM_IMG)))"
      ],
      "metadata": {
        "id": "_JaSAAy6nAIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TRANSFORMATION CENTRAL COMPLEX"
      ],
      "metadata": {
        "id": "9gXGs9LRvjO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Central_Complex_List = [Central_Complex_One,Central_Complex_Two]"
      ],
      "metadata": {
        "id": "YNFfnjwvnCWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Central_IMG = []\n",
        "\n",
        "for central_video in Central_Complex_List:\n",
        "    \n",
        "    Video_Path = central_video\n",
        "    \n",
        "    Video_Caption = cv2.VideoCapture(Video_Path)\n",
        "    \n",
        "    while Video_Caption.isOpened():\n",
        "        \n",
        "        _,frame = Video_Caption.read()\n",
        "        \n",
        "        if _ != True:\n",
        "            break\n",
        "            \n",
        "        if Video_Caption.isOpened():\n",
        "            \n",
        "            Transformation_IMG = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "            Resized_IMG = cv2.resize(Transformation_IMG,(180,180))\n",
        "            Central_IMG.append(Resized_IMG)\n",
        "            \n",
        "    Video_Caption.release()"
      ],
      "metadata": {
        "id": "RXWrxKSfnEgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Central_IMG))"
      ],
      "metadata": {
        "id": "toZCM7xynHxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(np.array(Central_IMG)))"
      ],
      "metadata": {
        "id": "C15cMU7BnJ88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TRANSFORMATION HEMIBRAIN"
      ],
      "metadata": {
        "id": "pf8Won7hzFsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Hemibrain_IMG = []\n",
        "\n",
        "Video_Path = Hemibrain\n",
        "\n",
        "Video_Caption = cv2.VideoCapture(Video_Path)\n",
        "\n",
        "while Video_Caption.isOpened():\n",
        "    \n",
        "    _,frame = Video_Caption.read()\n",
        "    \n",
        "    if _ != True:\n",
        "        break\n",
        "    if Video_Caption.isOpened():\n",
        "        Transformation_IMG = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "        Resized_IMG = cv2.resize(Transformation_IMG,(180,180))\n",
        "        Hemibrain_IMG.append(Resized_IMG)"
      ],
      "metadata": {
        "id": "8dNnfsk_nNIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Hemibrain_IMG))"
      ],
      "metadata": {
        "id": "a4MRiB9HnO_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(np.array(Hemibrain_IMG)))"
      ],
      "metadata": {
        "id": "pWb3KoiUnRGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TRANSFORMATION FULL CONNECTED"
      ],
      "metadata": {
        "id": "ySCLOKjvzLdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Connected_IMG = []\n",
        "\n",
        "Video_Path = Full_Connected\n",
        "\n",
        "Video_Caption = cv2.VideoCapture(Video_Path)\n",
        "\n",
        "while Video_Caption.isOpened():\n",
        "    \n",
        "    _,frame = Video_Caption.read()\n",
        "    \n",
        "    if _ != True:\n",
        "        break\n",
        "    if Video_Caption.isOpened():\n",
        "        Transformation_IMG = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "        Resized_IMG = cv2.resize(Transformation_IMG,(180,180))\n",
        "        Connected_IMG.append(Resized_IMG)"
      ],
      "metadata": {
        "id": "eZRmwoewnTB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Connected_IMG))"
      ],
      "metadata": {
        "id": "6Uw_J2PlnU8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(np.array(Connected_IMG)))"
      ],
      "metadata": {
        "id": "7FnDoksdnXEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VISION & ANALYSIS"
      ],
      "metadata": {
        "id": "V2ynEeDCzR29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FUNCTION"
      ],
      "metadata": {
        "id": "jndJtorWzTX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_single(image):\n",
        "    \n",
        "    figure = plt.figure(figsize=(7,7))\n",
        "    \n",
        "    Single_Image = image\n",
        "    \n",
        "    plt.xlabel(Single_Image.shape)\n",
        "    plt.ylabel(Single_Image.size)\n",
        "    plt.imshow(Single_Image)"
      ],
      "metadata": {
        "id": "cVsD-B6XnZVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_threshold(image):\n",
        "    \n",
        "    figure = plt.figure(figsize=(7,7))\n",
        "    \n",
        "    Single_Image = image\n",
        "    _,Threshold_Image = cv2.threshold(Single_Image,190,200,cv2.THRESH_BINARY)\n",
        "    \n",
        "    plt.xlabel(Threshold_Image.shape)\n",
        "    plt.ylabel(Threshold_Image.size)\n",
        "    plt.title(\"THRESHOLD\")\n",
        "    plt.imshow(Threshold_Image)"
      ],
      "metadata": {
        "id": "SKd04uGmnbWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reading_threshold(image):\n",
        "    \n",
        "    Single_Image = image\n",
        "    _,Threshold_Image = cv2.threshold(Single_Image,190,200,cv2.THRESH_BINARY)\n",
        "    \n",
        "    return Threshold_Image"
      ],
      "metadata": {
        "id": "_i-ZwL_AndVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_adaptive_threshold(image):\n",
        "    \n",
        "    figure = plt.figure(figsize=(7,7))\n",
        "    \n",
        "    Single_Image = image[:,:,0]\n",
        "    Adaptive_Image = cv2.adaptiveThreshold(Single_Image,20,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,9,2)\n",
        "    \n",
        "    plt.xlabel(Adaptive_Image.shape)\n",
        "    plt.ylabel(Adaptive_Image.size)\n",
        "    plt.title(\"ADAPTIVE\")\n",
        "    plt.imshow(Adaptive_Image)"
      ],
      "metadata": {
        "id": "Qe5Y7N7nnfoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reading_adaptive(image):\n",
        "    \n",
        "    Single_Image = image[:,:,0]\n",
        "    Adaptive_Image = cv2.adaptiveThreshold(Single_Image,20,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,9,2)\n",
        "    \n",
        "    return Adaptive_Image"
      ],
      "metadata": {
        "id": "rntyhvH1nhxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_canny(image):\n",
        "    \n",
        "    figure = plt.figure(figsize=(7,7))\n",
        "    \n",
        "    Single_Image = image\n",
        "    Canny_Image = cv2.Canny(Single_Image,10,100)\n",
        "    \n",
        "    plt.xlabel(Canny_Image.shape)\n",
        "    plt.ylabel(Canny_Image.size)\n",
        "    plt.title(\"CANNY\")\n",
        "    plt.imshow(Canny_Image)"
      ],
      "metadata": {
        "id": "7BtmKOvtnj-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reading_canny(image):\n",
        "    \n",
        "    Single_Image = image\n",
        "    Canny_Image = cv2.Canny(Single_Image,10,100)\n",
        "    \n",
        "    return Canny_Image"
      ],
      "metadata": {
        "id": "5jupL4Vsnmcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_bitwise_and(image):\n",
        "    \n",
        "    figure = plt.figure(figsize=(7,7))\n",
        "    \n",
        "    Single_Image = image\n",
        "    Threshold_Image = reading_threshold(Single_Image)\n",
        "    \n",
        "    Mask_For_Image = cv2.inRange(Single_Image,Single_Image,Threshold_Image)\n",
        "    Bitwise_And_Image = cv2.bitwise_and(Single_Image,Single_Image,mask=Mask_For_Image)\n",
        "    \n",
        "    plt.xlabel(Bitwise_And_Image.shape)\n",
        "    plt.ylabel(Bitwise_And_Image.size)\n",
        "    plt.title(\"BITWISE AND\")\n",
        "    plt.imshow(Bitwise_And_Image)"
      ],
      "metadata": {
        "id": "U-HE90Fenogi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_hessian(image,sigma,order):\n",
        "    \n",
        "    figure,axis = plt.subplots(1,2,figsize=(7,7))\n",
        "    \n",
        "    Single_Image = image\n",
        "    Gray_Image = cv2.cvtColor(Single_Image,cv2.COLOR_RGB2GRAY)\n",
        "    \n",
        "    Hessian_IMG = hessian_matrix(Gray_Image,sigma=sigma,order=order)\n",
        "    maxima_IMG,minima_IMG = hessian_matrix_eigvals(Hessian_IMG)\n",
        "    \n",
        "    axis[0].set_xlabel(maxima_IMG.shape)\n",
        "    axis[0].set_ylabel(maxima_IMG.size)\n",
        "    axis[0].set_title(\"MAX\")\n",
        "    axis[0].imshow(maxima_IMG,cmap=\"Greys_r\")\n",
        "    \n",
        "    axis[1].set_xlabel(minima_IMG.shape)\n",
        "    axis[1].set_ylabel(minima_IMG.size)\n",
        "    axis[1].set_title(\"MIN\")\n",
        "    axis[1].imshow(minima_IMG,cmap=\"Greys_r\")"
      ],
      "metadata": {
        "id": "XLSpepNnnqcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_skeleton(image):\n",
        "    \n",
        "    figure,axis = plt.subplots(1,2,figsize=(7,7))\n",
        "    \n",
        "    Single_Image = image\n",
        "    Gray_Image = cv2.cvtColor(Single_Image,cv2.COLOR_RGB2GRAY)\n",
        "    Threshold_Image = reading_threshold(Gray_Image)\n",
        "    Array_Image = np.array(Gray_Image > Threshold_Image).astype(int)\n",
        "    \n",
        "    Skeleton_Image = skimage.morphology.skeletonize(Array_Image)\n",
        "    \n",
        "    axis[0].set_xlabel(Gray_Image.shape)\n",
        "    axis[0].set_ylabel(Gray_Image.size)\n",
        "    axis[0].set_title(\"GRAY\")\n",
        "    axis[0].imshow(Gray_Image)\n",
        "    \n",
        "    axis[1].set_xlabel(Skeleton_Image.shape)\n",
        "    axis[1].set_ylabel(Skeleton_Image.size)\n",
        "    axis[1].set_title(\"SKELETON\")\n",
        "    axis[1].imshow(Skeleton_Image)"
      ],
      "metadata": {
        "id": "VbX2I3yInsl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reading_skeleton(image):\n",
        "    \n",
        "    Single_Image = image\n",
        "    Gray_Image = cv2.cvtColor(Single_Image,cv2.COLOR_RGB2GRAY)\n",
        "    Threshold_Image = reading_threshold(Gray_Image)\n",
        "    Array_Image = np.array(Gray_Image > Threshold_Image).astype(int)\n",
        "    \n",
        "    Skeleton_Image = skimage.morphology.skeletonize(Array_Image)\n",
        "    \n",
        "    return Skeleton_Image"
      ],
      "metadata": {
        "id": "oiR6T3vwnuxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_histogram(image):\n",
        "    \n",
        "    Single_Image = image\n",
        "    \n",
        "    colors = (\"red\", \"green\", \"blue\")\n",
        "    channel_dim = (0, 1, 2)\n",
        "\n",
        "    plt.xlim([0, 255])\n",
        "    plt.ylim([0, 150])\n",
        "\n",
        "    for channel_id, c in zip(channel_dim, colors):\n",
        "        histogram, bin_edges = np.histogram(\n",
        "            Single_Image[:, :, channel_id], bins=256, range=(0, 256)\n",
        "        )\n",
        "        plt.plot(bin_edges[0:-1], histogram, color=c)\n",
        "\n",
        "    plt.xlabel(\"Color value\")\n",
        "    plt.ylabel(\"Pixels\")"
      ],
      "metadata": {
        "id": "R-7eWGwxnwk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SIMPLE GENERAL"
      ],
      "metadata": {
        "id": "NmViiFovzhHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(\"dark_background\")"
      ],
      "metadata": {
        "id": "i2nZjdPVnyp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_single(Neuron_IMG[0])"
      ],
      "metadata": {
        "id": "ocPrUZPqn1DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_single(EM_IMG[0])"
      ],
      "metadata": {
        "id": "tC1KIwC2n3QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_single(Central_IMG[0])"
      ],
      "metadata": {
        "id": "0JZsJpgln5z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_single(Hemibrain_IMG[0])"
      ],
      "metadata": {
        "id": "WF_d2mKRn9fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_single(Connected_IMG[0])"
      ],
      "metadata": {
        "id": "qAxia22Kn_dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure,axis = plt.subplots(5,5,figsize=(10,10))\n",
        "\n",
        "for indexing,operation in enumerate(axis.flat):\n",
        "    \n",
        "    Picking_Image = Neuron_IMG[indexing]\n",
        "    operation.set_xlabel(Picking_Image.shape)\n",
        "    operation.set_ylabel(Picking_Image.size)\n",
        "    operation.set_title(\"NEURON\")\n",
        "    operation.imshow(Picking_Image)\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2jigEslVoBiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### THRESHOLD"
      ],
      "metadata": {
        "id": "R9IBFJuUzntB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_threshold(Neuron_IMG[0])"
      ],
      "metadata": {
        "id": "koU3C6CQoDoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_threshold(Neuron_IMG[10])"
      ],
      "metadata": {
        "id": "21PwCf8loGtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_threshold(Neuron_IMG[200])"
      ],
      "metadata": {
        "id": "VP9pGdDyoI-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_threshold(EM_IMG[1000])"
      ],
      "metadata": {
        "id": "j_DjR0QToLlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_threshold(Central_IMG[123])"
      ],
      "metadata": {
        "id": "g3Z__17CoQzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_threshold(Connected_IMG[3])"
      ],
      "metadata": {
        "id": "nfXA3xBEoTDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CANNY"
      ],
      "metadata": {
        "id": "j2Ui7Palz0Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_canny(Neuron_IMG[10])"
      ],
      "metadata": {
        "id": "ZYDWCAhdoVbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_canny(Neuron_IMG[128])"
      ],
      "metadata": {
        "id": "OYEhe3vZoXl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_canny(Neuron_IMG[233])"
      ],
      "metadata": {
        "id": "36gclS_eoZrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_canny(Connected_IMG[3])"
      ],
      "metadata": {
        "id": "Z2s9J9tmobr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_canny(Central_IMG[3])"
      ],
      "metadata": {
        "id": "JNT5GkUtoeK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### HESSIAN"
      ],
      "metadata": {
        "id": "Tiofrfdnz5Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_hessian(Central_IMG[3],0.15,\"rc\")"
      ],
      "metadata": {
        "id": "FDqbe5qNogih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_hessian(Neuron_IMG[3],0.15,\"rc\")"
      ],
      "metadata": {
        "id": "-T5wA-S7oi5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_hessian(Neuron_IMG[300],0.15,\"rc\")"
      ],
      "metadata": {
        "id": "JoJV1hXFol6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_hessian(EM_IMG[300],0.15,\"rc\")"
      ],
      "metadata": {
        "id": "jnBj2s_SooWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_hessian(EM_IMG[1378],0.15,\"rc\")"
      ],
      "metadata": {
        "id": "Avwom-Czoq0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SKELETON"
      ],
      "metadata": {
        "id": "iWDj5KZxz9X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_skeleton(Neuron_IMG[0])"
      ],
      "metadata": {
        "id": "WO5gyiqOos-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_skeleton(Neuron_IMG[100])"
      ],
      "metadata": {
        "id": "jz3GW7qbou_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_skeleton(Central_IMG[100])"
      ],
      "metadata": {
        "id": "XSz6lpQLow-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.imshow(reading_skeleton(Neuron_IMG[200]))\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "CYBmyILlozKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.imshow(reading_skeleton(Neuron_IMG[300]))\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "bffvuRZYo1N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.imshow(reading_skeleton(Central_IMG[300]))\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "8H5gXquCo3N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.imshow(reading_skeleton(EM_IMG[1300]))\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "LzBHxYUJo5rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure,axis = plt.subplots(5,5,figsize=(10,10))\n",
        "\n",
        "for indexing,operation in enumerate(axis.flat):\n",
        "    \n",
        "    Picking_Image = Neuron_IMG[indexing*10]\n",
        "    Skeleton_Image = reading_skeleton(Picking_Image)\n",
        "    \n",
        "    operation.set_xlabel(Skeleton_Image.shape)\n",
        "    operation.set_ylabel(Skeleton_Image.size)\n",
        "    operation.set_title(\"NEURON\")\n",
        "    operation.imshow(Skeleton_Image)\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZCMd3CLgo7-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### HISTOGRAM"
      ],
      "metadata": {
        "id": "YSguoCAe0DbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_histogram(Neuron_IMG[300])"
      ],
      "metadata": {
        "id": "YnN6XERmo-T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_histogram(Neuron_IMG[3])"
      ],
      "metadata": {
        "id": "ty_W6R2UpA01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_histogram(Neuron_IMG[123])"
      ],
      "metadata": {
        "id": "RD3jTzoUpFLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_histogram(Neuron_IMG[323])"
      ],
      "metadata": {
        "id": "vAzVuU99pHF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_histogram(Central_IMG[23])"
      ],
      "metadata": {
        "id": "ymqIzV77pJHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_histogram(Central_IMG[2])"
      ],
      "metadata": {
        "id": "zFXFPixKpLBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DC-GAN STEPS"
      ],
      "metadata": {
        "id": "4k-dtLvc0Hz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PARAMETERS"
      ],
      "metadata": {
        "id": "GYgmS_Ne0J5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 3\n",
        "vector_noise_shape = 180\n",
        "count_example = 9\n",
        "batch_size = 3\n",
        "count_buffer_time = 60000"
      ],
      "metadata": {
        "id": "CT031csDpM6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = tf.random.normal([count_example,vector_noise_shape])"
      ],
      "metadata": {
        "id": "Nd4VAViApPUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DATA TRANSFORMATION"
      ],
      "metadata": {
        "id": "0ZdpmR-a0QyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_Train = np.array(Neuron_IMG)\n",
        "\n",
        "X_Train = X_Train.astype(\"float32\")\n",
        "\n",
        "X_Train = (X_Train - 127.5) / 127.5"
      ],
      "metadata": {
        "id": "J8dt0fSvpRCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NEURON SHAPE: \",X_Train.shape)"
      ],
      "metadata": {
        "id": "TBS4V7QopSp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_Train = np.array(Central_IMG)\n",
        "\n",
        "Y_Train = Y_Train.astype(\"float32\")\n",
        "\n",
        "Y_Train = (Y_Train - 127.5) / 127.5"
      ],
      "metadata": {
        "id": "pg3tKnxgpUcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NEURON SHAPE: \",Y_Train.shape)"
      ],
      "metadata": {
        "id": "S6XGlzrQpW5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_Train[0])"
      ],
      "metadata": {
        "id": "7i8kehOGpY_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_Train[600])"
      ],
      "metadata": {
        "id": "h1hgUBZJpddk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Y_Train[0])"
      ],
      "metadata": {
        "id": "KjfWnLH4pfvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Y_Train[652])"
      ],
      "metadata": {
        "id": "p5nk22drphyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_Data = tf.data.Dataset.from_tensor_slices(Y_Train).shuffle(count_buffer_time).batch(batch_size) # for connected central complex neurons"
      ],
      "metadata": {
        "id": "KdydEdbipkOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_Data_Two = tf.data.Dataset.from_tensor_slices(X_Train).shuffle(count_buffer_time).batch(batch_size) # for specific neurons, if you want"
      ],
      "metadata": {
        "id": "Du2mU6qapo-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Train_Data.element_spec)"
      ],
      "metadata": {
        "id": "XCpd7e3Jppjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Train_Data_Two.element_spec)"
      ],
      "metadata": {
        "id": "W0tX4fEhprlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GENERATOR PROCESS"
      ],
      "metadata": {
        "id": "e5Tuvb220Xue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Generator_Model():\n",
        "    \n",
        "    \n",
        "    Model = Sequential()\n",
        "    #\n",
        "    Model.add(Dense(90*90*128,use_bias=False,input_shape=(180,)))\n",
        "    Model.add(BatchNormalization())\n",
        "    Model.add(LeakyReLU())\n",
        "    #\n",
        "    Model.add(Reshape((90,90,128)))\n",
        "    #\n",
        "    Model.add(Conv2DTranspose(128,(3,3),padding=\"same\",use_bias=False))\n",
        "    Model.add(BatchNormalization())\n",
        "    Model.add(LeakyReLU())\n",
        "    \n",
        "    Model.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', use_bias=False))\n",
        "    Model.add(BatchNormalization())\n",
        "    Model.add(LeakyReLU())\n",
        "    #\n",
        "    Model.add(Conv2DTranspose(3,(3,3),padding=\"same\",use_bias=False,activation=\"tanh\"))\n",
        "    \n",
        "    \n",
        "    return Model"
      ],
      "metadata": {
        "id": "vFtdCG-lptZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generator = Generator_Model()"
      ],
      "metadata": {
        "id": "yM21CfZVpvW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Generator.summary())"
      ],
      "metadata": {
        "id": "rDVBKJ4RpxIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DISCRIMINATOR PROCESS"
      ],
      "metadata": {
        "id": "mcjPIVJv0df2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Discriminator_Model():\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(64,(3,3),padding=\"same\",input_shape=[180,180,3]))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    \n",
        "    model.add(Conv2D(128,(3,3),padding=\"same\"))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "KUgVfWJIpy9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Discriminator = Discriminator_Model()"
      ],
      "metadata": {
        "id": "Jvblzx9xp16h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Discriminator.summary())"
      ],
      "metadata": {
        "id": "4I0aa-uRp39u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### OPTIMIZERS"
      ],
      "metadata": {
        "id": "Txrp5-Zx0uTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Generator_Optimizer = tf.keras.optimizers.RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8)\n",
        "Discriminator_Optimizer = tf.keras.optimizers.RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8)"
      ],
      "metadata": {
        "id": "jxNKp3JMp5tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LOSS FUNCTION"
      ],
      "metadata": {
        "id": "Hy9WEuec0xOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Loss_Function = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "90lAkLTep8cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Discriminator_Loss(real_out,fake_out):\n",
        "    \n",
        "    real_loss = Loss_Function(tf.ones_like(real_out),real_out)\n",
        "    fake_loss = Loss_Function(tf.zeros_like(fake_out),fake_out)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    \n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "mDy9FVq8p-X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Generator_Loss(fake_out):\n",
        "    \n",
        "    return Loss_Function(tf.ones_like(fake_out),fake_out)"
      ],
      "metadata": {
        "id": "yAgU24YyqALo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GENERATING AND SAVING IMAGE"
      ],
      "metadata": {
        "id": "tij8mmQh02Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_and_save_images(model, epoch, test_input):\n",
        "    \n",
        "    predictions = model(test_input, training=False)\n",
        "    fig = plt.figure(figsize=(12, 12))\n",
        "    \n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('output_image{:04d}.png'.format(epoch))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6uPNXhINqDbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TRAINING STEP"
      ],
      "metadata": {
        "id": "suEYFO3W06dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Step(images):\n",
        "    \n",
        "    random_noise_vector = tf.random.normal([batch_size,vector_noise_shape])\n",
        "    \n",
        "    with tf.GradientTape() as Generator_Tape, tf.GradientTape() as Discriminator_Tape:\n",
        "        Generator_Fake_Images = Generator(random_noise_vector,training=False)\n",
        "        \n",
        "        real_out = Discriminator(images,training=True)\n",
        "        fake_out = Discriminator(Generator_Fake_Images,training=True)\n",
        "        \n",
        "        Generator_Loss_Out = Generator_Loss(fake_out)\n",
        "        Discriminator_Loss_Out = Discriminator_Loss(real_out,fake_out)\n",
        "        \n",
        "    Generator_Gradients = Generator_Tape.gradient(Generator_Loss_Out,Generator.trainable_variables)\n",
        "    Discriminator_Gradients = Discriminator_Tape.gradient(Discriminator_Loss_Out,Discriminator.trainable_variables)\n",
        "    \n",
        "    Generator_Optimizer.apply_gradients(zip(Generator_Gradients,Generator.trainable_variables))\n",
        "    Discriminator_Optimizer.apply_gradients(zip(Discriminator_Gradients,Discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "5sn-mTMFqFGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TRAINING"
      ],
      "metadata": {
        "id": "ivIapH1h0_6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Training(dataset,iterations):\n",
        "    \n",
        "    for epoch in range(iterations):\n",
        "        \n",
        "        start = time.time()\n",
        "        \n",
        "        for image_batch in dataset:\n",
        "            Train_Step(image_batch)\n",
        "            \n",
        "        display.clear_output(wait=True)\n",
        "        display_and_save_images(Generator,epoch+1,seed)\n",
        "    \n",
        "    display.clear_output(wait=True)\n",
        "    display_and_save_images(Generator,epoch,seed)"
      ],
      "metadata": {
        "id": "ZCvU2b4BqHKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TRAIN FOR COMPLEX NEURON"
      ],
      "metadata": {
        "id": "RJfD6YX71C9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training(Train_Data,iterations)"
      ],
      "metadata": {
        "id": "8mx__L1dqJI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PREDICTION FOR COMPLEX NEURON"
      ],
      "metadata": {
        "id": "THUb2Q_v1c6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Predict_Generator_Noise = tf.random.normal(shape=[50,vector_noise_shape])"
      ],
      "metadata": {
        "id": "8poryblzqLgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generator_Predict = Generator(Predict_Generator_Noise)"
      ],
      "metadata": {
        "id": "yE808kbeq7Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure, axes = plt.subplots(nrows=3,ncols=3,figsize=(10,10))\n",
        "\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    Prediction_Output = Generator_Predict[i]\n",
        "    ax.imshow(Prediction_Output,cmap=\"gray\")\n",
        "    ax.set_xlabel(Generator_Predict[i].shape)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7s4IRcEkq98w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(Generator_Predict[25])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TvKURIpJq_ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(Generator_Predict[20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WQinZvQarBXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(Generator_Predict[5])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MhL5I4xRrDFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(Generator_Predict[3])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gpqU6aGUrE4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(Generator_Predict[44])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Mgn-Dx8rG1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TRAIN FOR SPECIFIC NEURON"
      ],
      "metadata": {
        "id": "avCJhdJ81qpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training(Train_Data_Two,iterations)"
      ],
      "metadata": {
        "id": "HXJ2ZKNSrIq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SN_Predict_Generator_Noise = tf.random.normal(shape=[50,vector_noise_shape])"
      ],
      "metadata": {
        "id": "ifu2aKVFrKi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generator_Predict_SN = Generator(SN_Predict_Generator_Noise)"
      ],
      "metadata": {
        "id": "g-fZ68cprNGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure, axes = plt.subplots(nrows=3,ncols=3,figsize=(10,10))\n",
        "\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    Prediction_Output = Generator_Predict_SN[i]\n",
        "    ax.imshow(Prediction_Output,cmap=\"gray\")\n",
        "    ax.set_xlabel(Generator_Predict_SN[i].shape)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UU9Pw0eHrPZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(Generator_Predict_SN[20])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0EL0-AWKrRJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(Generator_Predict_SN[2])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NH_ajfFVrS_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(Generator_Predict_SN[33])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-wgDnA27rUsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(Generator_Predict_SN[45])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DeB4g5E3rWbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Tk61I5QrYSQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}